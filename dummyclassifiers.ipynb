{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ask1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnwrHphPTKxb"
      },
      "source": [
        "# **Νευρωνικά Δίκτυα και Ευφυή Υπολογιστικά Συστήματα**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKFwQ8vuU7mw"
      },
      "source": [
        "### **Άσκηση 1. Επιβλεπόμενη Μάθηση: Ταξινόμηση. Μελέτη datasets του UCI Machine Learning Repository**\n",
        "##### Μαρίνος Τζανίκος 03113147, el13147@mail.ntua.gr\n",
        "##### Γιώργος Γκανάς 03116095, el16095@mail.ntua.gr\n",
        "##### Παναγιώτης Αϊβασιλιώτης 03116176, el16176@mail.ntua.gr "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GYIi1GwD6jO",
        "outputId": "c82453f2-46c9-4db2-abcc-06899cf097c0"
      },
      "source": [
        "!pip install --upgrade pip \n",
        "!pip install --upgrade scikit-learn \n",
        "!pip install --upgrade numpy \n",
        "!pip install --upgrade scipy \n",
        "!pip install --upgrade pandas "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (20.2.4)\n",
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.23.2)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.4)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.5.4)\n",
            "Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.19.4)\n",
            "Requirement already up-to-date: scipy in /usr/local/lib/python3.6/dist-packages (1.5.4)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.19.4)\n",
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.4)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAfQO7arh_jT"
      },
      "source": [
        "#### **Βασικές πληροφορίες**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6rcabbOWNdA"
      },
      "source": [
        "**Εισαγωγή του dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BIib37nsYVaV",
        "outputId": "983af888-2995-4048-e73d-1fde22a81270"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"crx.data\", header=None)\n",
        "#Show the first 5 samples of the dataframe\n",
        "df.head(n=5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b</td>\n",
              "      <td>30.83</td>\n",
              "      <td>0.000</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.25</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00202</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>58.67</td>\n",
              "      <td>4.460</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>3.04</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>6</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00043</td>\n",
              "      <td>560</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>24.50</td>\n",
              "      <td>0.500</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>1.50</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00280</td>\n",
              "      <td>824</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b</td>\n",
              "      <td>27.83</td>\n",
              "      <td>1.540</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>3.75</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>5</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00100</td>\n",
              "      <td>3</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b</td>\n",
              "      <td>20.17</td>\n",
              "      <td>5.625</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.71</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>s</td>\n",
              "      <td>00120</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
              "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n",
              "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
              "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
              "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
              "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-YQB8bCYsD5"
      },
      "source": [
        "**Παρουσίαση του dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrDiFSG-Y26E"
      },
      "source": [
        "To dataset περιγράφει την έκβαση των αιτήσεων για πιστωτικές κάρτες με βάση κάποια χαρακτηριστικά.Δηλαδή αν η αίτηση κάποιου για πιστωτική κάρτα, εγκρίθηκε ή όχι.Στόχος μας είναι με χρήση επιβλεπόμενης μάθησης και χωρίς να ξέρουμε την πραγματική ερμηνεία των δεδομένων να δημιουργήσουμε ένα συστήμα που θα μπορεί να χαρακτηρίζει όσο το δυνατόν καλύτερα αν η έκβαση μίας υποψηφίας αίτησης θα είναι θετική ή αρνητική."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1kErmr-hu8A"
      },
      "source": [
        "**Αριθμός δειγμάτων και χαρακτηριστικών, είδος χαρακτηριστικών. Υπάρχουν μη διατεταγμένα χαρακτηριστικά και ποια είναι αυτά;**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4WQVKW1h0tE"
      },
      "source": [
        "Το dataset περιέχει 690 δείγματα.Kάθε δείγμα αποτελείται από 15 χαρακτηριστικά τα οποία είναι κατηγορικά ή αριθμητικά και των οποίων η πραγματική ερμηνεία δεν μας δίνεται.Τα διατεταγμένα χαρακτηριστικά είναι μόνο τα αριθμητικά.Ακόμα κάθε δείγμα περιέχει μία ετικέτα που μας δείχνει την έκβαση που είχε η εν λόγω αίτηση.Πιο συγκεκριμένα έχουμε τα εξής σχετικά με τις πληροφορίες που περιέχει ένα δείγμα:\n",
        "\n",
        "A1:\tb, a.  \n",
        "A2:\tcontinuous.  \n",
        "A3:\tcontinuous.  \n",
        "A4:\tu, y, l, t.  \n",
        "A5:\tg, p, gg.  \n",
        "A6:\tc, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.  \n",
        "A7:\tv, h, bb, j, n, z, dd, ff, o.  \n",
        "A8:\tcontinuous.  \n",
        "A9: t, f.  \n",
        "A10: t, f.  \n",
        "A11: continuous.  \n",
        "A12: t, f.  \n",
        "A13: g, p, s.  \n",
        "A14: continuous.  \n",
        "A15: continuous.  \n",
        "A16: +,- (class attribute)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByUr4FIkGTKW"
      },
      "source": [
        "Επομένως έχουμε οτι τα χαρακτηριστικά Α2,Α3,Α8,Α11,Α14,Α15 είναι συνεχή και τα υπόλοιπα 10 κατηγορικά."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXxtBMr2peAw"
      },
      "source": [
        "**Υπάρχουν επικεφαλίδες; Αρίθμηση γραμμών;**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eimPL-4SpkwX"
      },
      "source": [
        "Όχι, τα δεδομένα μας βρίσκονται σε raw μορφή μέσα στο αρχείο και επομένως δεν έχουν ούτε επικεφαλίδες ούτε αρίθμηση γραμμών."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqlIMs_nq-rH"
      },
      "source": [
        "**Ποιες είναι οι ετικέτες των κλάσεων και σε ποια κολόνα βρίσκονται;**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0amgCbtarCDv"
      },
      "source": [
        "Οι ετικέτες των κλάσεων βρίσκονται στην 16η κολόνα και είναι είτε \"+\" δηλαδή θετική έκβαση της αίτησης είτε \"-\" δηλαδή αρνητική έκβαση της αίτησης."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWuBXSnirgTY",
        "outputId": "48fd4b15-427f-4fef-e897-3ade55a7e92a"
      },
      "source": [
        "unique_labels = df.iloc[:,-1].unique()\n",
        "print(\"Unique labels of samples: {0}\".format(unique_labels))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique labels of samples: ['+' '-']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWoOVrlssd5l"
      },
      "source": [
        "**Χρειάστηκε να κάνετε μετατροπές στα αρχεία text και ποιες?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nnl53kYNw_OO"
      },
      "source": [
        "Οχι δεν χρειάστηκε να γίνει κάποια μετατροπή στα αρχεία text.Ωστόσο κρίθηκε απαραίτητο να γίνει μία κωδικοποίηση των ετικετών κλάσης από -,+ σε 0,1 ώστε τα δεδομένα μας να είναι συμβατά με το scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRrPkAHvz2N7"
      },
      "source": [
        "labels_df = df.iloc[:,-1] # labels in the last column\n",
        "features_df = df.iloc[:,:-1] # features in all columns but the last\n",
        "\n",
        "mapping = {'-' : 0, '+' : 1} # mapping for labels\n",
        "labels_df = labels_df.replace(mapping)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri788AEJ20nr"
      },
      "source": [
        "**Υπάρχουν απουσιάζουσες τιμές; Πόσα είναι τα δείγματα με απουσιάζουσες τιμές και ποιο το ποσοστό τους επί του συνόλου;**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_xixCOz25w0"
      },
      "source": [
        "Παρατηρούμε ότι οι απουσιάζουσες τιμές εμφανίζονται με \"?\" μέσα στο αρχείο εισόδου και δεν υπάρχει καμία απουσιάζουσα ετικέτα."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwIWHZS53Azv"
      },
      "source": [
        "df.replace('?', np.NaN, inplace=True) # replace all ? with np.NaN\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86knYAaRYs1F",
        "outputId": "dfd015a7-9522-4245-b0d2-0c919f6c2704"
      },
      "source": [
        "df.isnull().sum().sum() # how many missing values we have"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB2FwlKEZAqR",
        "outputId": "33792187-5d45-45d6-caa7-347da0b24d5e"
      },
      "source": [
        "sum([True for idx,row in df.iterrows() if any(row.isnull())]) # how many samples have missing values"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOj1CK0qAv72"
      },
      "source": [
        "Επομένως υπάρχουν συνολικά 67 απουσιάζουσες τιμές σε 37 εκ των δειγμάτων, που αντιστοιχούν στο 5,3% του συνόλου."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hncYyqEvDLJV"
      },
      "source": [
        "**Ποιος είναι ο αριθμός των κλάσεων και τα ποσοστά δειγμάτων τους επί του συνόλου; Αν θεωρήσουμε ότι ένα dataset είναι μη ισορροπημένο αν μια οποιαδήποτε κλάση είναι 1.5 φορά πιο συχνή από κάποια άλλη (60%-40% σε binary datasets) εκτιμήστε την ισορροπία του dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHHIjgd_dgdm",
        "outputId": "aed34b83-0bfe-4891-85ea-b40fd2b5cc44"
      },
      "source": [
        "np_labels = labels_df.values.flatten() # convert labels dataframe to numpy array\n",
        "frequencies = np.bincount(np_labels)\n",
        "total_samples = np_labels.shape[0]\n",
        "percentages = (frequencies / total_samples) * 100\n",
        "\n",
        "print(\"Class frequencies: {0}\".format(frequencies))\n",
        "\n",
        "print(\"Class percentages: {0}\".format(percentages))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class frequencies: [383 307]\n",
            "Class percentages: [55.50724638 44.49275362]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIS3xaLXf0i2"
      },
      "source": [
        "Βλέπουμε ότι τα ποσοστά δειγμάτων επί του συνόλου των δύο κλάσεων βρίσκονται κοντά στο 50%, επομένως το dataset είναι ισορροπημένο."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnL1IsBSDOg4"
      },
      "source": [
        "**Διαχωρίστε σε train και test set. Εάν υπάρχουν απουσιάζουσες τιμές και μη διατεταγμένα\n",
        "χαρακτηριστικά διαχειριστείτε τα και αιτιολογήστε τις επιλογές σας.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiTNljpTtOrr"
      },
      "source": [
        "Αφού χωρίσουμε το dataset σε train και test set θα αντικαταστήσουμε τις απουσιάζουσες τιμές καθώς η είσοδος στους αλγορίθμους μηχανικής μάθησης πρέπει να είναι πλήρης.Για το λόγο αυτόν,\n",
        "Θα χρησιμοποιήσουμε το μετασχηματιστή “Imputer” του scikit learn που αντικαθιστά κάθε απουσιάζουσα τιμή χαρακτηριστικού με τη μέση τιμή (συνεχείς μεταβλητές) ή την πιο συχνή τιμή (κατηγορικές μεταβλητές).\n",
        "Ο μετασχηματισμός με Imputer γίνεται στην απόλυτη αρχή της προεπεξεργασίας.\n",
        "Ακόμα πρέπει να"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7I-k9wnOh-K"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "#Split our dataframe intο train and test set\n",
        "trainData, testData, trainLabels, testLabels = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.2, random_state=40)\n",
        "\n",
        "#Split dataframes into categorical and continuous features dataframes\n",
        "trainData_continuous = trainData.drop([0,3,4,5,6,8,9,11,12], axis=1)\n",
        "trainData_categorical = trainData.drop([1,2,7,10,13,14], axis=1)\n",
        "testData_continuous = testData.drop([0,3,4,5,6,8,9,11,12], axis=1)\n",
        "testData_categorical = testData.drop([1,2,7,10,13,14], axis=1)\n",
        "\n",
        "#Impute the missing values on continuous features\n",
        "imp = SimpleImputer(missing_values=np.NaN,strategy='mean')\n",
        "itrainData_continuous = pd.DataFrame(imp.fit_transform(trainData_continuous))\n",
        "itrainData_continuous.columns=[1,2,7,10,13,14]\n",
        "itestData_continuous = pd.DataFrame(imp.fit_transform(testData_continuous))\n",
        "itestData_continuous.columns=[1,2,7,10,13,14]\n",
        "\n",
        "#Impute the missing values on categorical features\n",
        "imp = SimpleImputer(missing_values=np.NaN, strategy=\"most_frequent\")\n",
        "itrainData_categorical = pd.DataFrame(imp.fit_transform(trainData_categorical))\n",
        "itrainData_categorical.columns=[0,3,4,5,6,8,9,11,12]\n",
        "itestData_categorical = pd.DataFrame(imp.fit_transform(testData_categorical))\n",
        "itestData_categorical.columns=[0,3,4,5,6,8,9,11,12]\n",
        "\n",
        "#Merge dataframes and reorder indexes to form the original ones imputed\n",
        "itrainData = pd.concat([itrainData_categorical, itrainData_continuous], axis=1)\n",
        "itrainData = itrainData.reindex(sorted(itrainData.columns), axis=1)\n",
        "\n",
        "itestData = pd.concat([itestData_categorical, itestData_continuous], axis=1)\n",
        "itestData = itestData.reindex(sorted(itestData.columns), axis=1)\n",
        "\n",
        "#Convert categorical features to binary , we have to join the two data before this step\n",
        "Data_dummies = pd.get_dummies(pd.concat([itrainData,itestData], join=\"outer\", axis=0),columns=[0,3,4,5,6,8,9,11,12])\n",
        "trainData_dummies = Data_dummies.iloc[:itrainData.shape[0],:]\n",
        "testData_dummies = Data_dummies.iloc[itrainData.shape[0]:,:]\n",
        "\n",
        "#Convert to numeric values and numpy arrays, using symbolic names\n",
        "X_train = trainData_dummies.apply(pd.to_numeric).values\n",
        "X_test = testData_dummies.apply(pd.to_numeric).values\n",
        "Y_train = trainLabels.values.flatten()\n",
        "Y_test =  testLabels.values.flatten()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eub0WauWiJqH"
      },
      "source": [
        "#### **Baseline classification** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmpcgGHyS5mb",
        "outputId": "e3c50f15-cfee-42a0-cd55-e1ad3eccbe71"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "dc_uniform = DummyClassifier(strategy=\"uniform\")\n",
        "dc_constant_minus = DummyClassifier(strategy=\"constant\", constant=\"-\")\n",
        "dc_constant_plus = DummyClassifier(strategy=\"constant\", constant=\"+\")\n",
        "dc_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
        "dc_stratified = DummyClassifier(strategy=\"stratified\")\n",
        "\n",
        "dc_uniform.fit(X_train, Y_train)\n",
        "dc_constant_minus.fit(X_train, Y_train)\n",
        "dc_constant_plus.fit(X_train, Y_train)\n",
        "dc_most_frequent.fit(X_train, Y_train)\n",
        "dc_stratified.fit(X_train, Y_train)\n",
        "\n",
        "pred_uni = dc_uniform.predict(X_test)\n",
        "pred_const_minus = dc_constant_minus.predict(X_test)\n",
        "pred_const_plus = dc_constant_plus.predict(X_test)\n",
        "pred_freq = dc_most_frequent.predict(X_test)\n",
        "pred_strat = dc_stratified.predict(X_test)\n",
        "\n",
        "print(\"The DummyClassifier with uniform strategy: \\n\" + fscore_report(Y_test,pred_uni))\n",
        "print(\"The DummyClassifier with constant minus strategy: \\n\" + classification_report(Y_test,pred_const_minus))\n",
        "print(\"The DummyClassifier with constant plus strategy: \\n\" + classification_report(Y_test,pred_const_plus))\n",
        "print(\"The DummyClassifier with frequent strategy: \\n\" + classification_report(Y_test,pred_freq))\n",
        "print(\"The DummyClassifier with stratified strategy: \\n\" + classification_report(Y_test,pred_strat))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The DummyClassifier with uniform strategy: \n",
            "[Micro] Precision: 0.49 Recall: 0.49, F1: 0.49 \n",
            "[Macro] Precision: 0.49 Recall: 0.49, F1: 0.49\n",
            "\n",
            "The DummyClassifier with constant minus strategy: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.00      0.00      0.00        65\n",
            "           -       0.53      1.00      0.69        73\n",
            "\n",
            "    accuracy                           0.53       138\n",
            "   macro avg       0.26      0.50      0.35       138\n",
            "weighted avg       0.28      0.53      0.37       138\n",
            "\n",
            "The DummyClassifier with constant plus strategy: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.47      1.00      0.64        65\n",
            "           -       0.00      0.00      0.00        73\n",
            "\n",
            "    accuracy                           0.47       138\n",
            "   macro avg       0.24      0.50      0.32       138\n",
            "weighted avg       0.22      0.47      0.30       138\n",
            "\n",
            "The DummyClassifier with frequent strategy: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.00      0.00      0.00        65\n",
            "           -       0.53      1.00      0.69        73\n",
            "\n",
            "    accuracy                           0.53       138\n",
            "   macro avg       0.26      0.50      0.35       138\n",
            "weighted avg       0.28      0.53      0.37       138\n",
            "\n",
            "The DummyClassifier with stratified strategy: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.43      0.45      0.44        65\n",
            "           -       0.49      0.48      0.49        73\n",
            "\n",
            "    accuracy                           0.46       138\n",
            "   macro avg       0.46      0.46      0.46       138\n",
            "weighted avg       0.46      0.46      0.46       138\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAIIJwXHeXVm"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "pred_gnb = gnb.predict(X_test)\n",
        "\n",
        "print(\"The GaussianNB Classifier: \\n\" + fscore_report(y_test,pred_gnb))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqe_COT0jl0K"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# kNN Classifier, default k=5\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train,y_train)\n",
        "pred_knn = knn.predict(X_test)\n",
        "\n",
        "print(\"The KNeighborsClassifier with n_neighbors=5: \\n\" + fscore_report(y_test,pred_knn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veGeRITJ75pl"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def fscore_report(y_test, y_pred):\n",
        "  #f1 micro\n",
        "  precision_micro = precision_recall_fscore_support(y_test, y_pred, average='micro')[0]\n",
        "  recall_micro = precision_recall_fscore_support(y_test, y_pred, average='micro')[1]\n",
        "  f1_micro = precision_recall_fscore_support(y_test, y_pred, average='micro')[2]\n",
        "  #f1 macro\n",
        "  precision_macro = precision_recall_fscore_support(y_test, y_pred, average='macro')[0]\n",
        "  recall_macro = precision_recall_fscore_support(y_test, y_pred, average='macro')[1]\n",
        "  f1_macro = precision_recall_fscore_support(y_test, y_pred, average='macro')[2]\n",
        "  return (\"[Micro] Precision: {0} Recall: {1}, F1: {2} \\n[Macro] Precision: {3} Recall: {4}, F1: {5}\\n\".format(round(precision_micro,2), round(recall_micro,2), round(f1_micro,2), round(precision_macro,2), round(recall_macro,2), round(f1_macro,2)))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyyYl7RP774o"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_cnf_clfs(clfs, X_test, y_test, classes):\n",
        "  fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15,10))\n",
        "  for clf, ax in zip(clfs, axes.flatten()):\n",
        "    split_title = str(clf).replace(\")\", \"\").split(\"(\")\n",
        "    clf_name = split_title[0]\n",
        "\n",
        "    if (clf_name == \"DummyClassifier\"):\n",
        "        clf_title = clf_name + split_title[1].split(\",\")[2]\n",
        "    elif (clf_name == \"GNB......\"):\n",
        "        clf_title = clf_name\n",
        "    elif (clf_name == \"KNeighborsClassifier\"):\n",
        "        clf_title = clf_name + split_title[1].split(\",\")[5]\n",
        "\n",
        "    disp = plot_confusion_matrix(clf, X_test, y_test,display_labels=classes,cmap=plt.cm.Blues,normalize=None,ax=ax)\n",
        "    disp.ax_.set_title(clf_title)\n",
        "  plt.tight_layout()\n",
        "  plt.show(disp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HksZcB8NLBgi"
      },
      "source": [
        "clfs = [knn,gnb,dc_uniform, dc_constant_minus, dc_constant_plus, dc_most_frequent, dc_stratified]\n",
        "plot_cnf_clfs(clfs,X_test, y_test,[\"+\", \"-\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ND_ziBCWxM"
      },
      "source": [
        "#### **Optimisation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fErMDA6gCWxM"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "selector = VarianceThreshold()\n",
        "mscaler = MinMaxScaler()\n",
        "sscaler = StandardScaler()\n",
        "pca = PCA()\n",
        "\n",
        "pipe_uniform = Pipeline(steps=[('selector', selector), ('pca', pca)\\\n",
        "                               , ('dc_uniform', dc_uniform)], memory = 'tmp')\n",
        "pipe_constant_minus = Pipeline(steps=[('selector', selector) , ('pca', pca)\\\n",
        "                                      , ('dc_constant_minus', dc_constant_minus)], memory = 'tmp')\n",
        "pipe_constant_plus = Pipeline(steps=[('selector', selector), ('pca', pca)\\\n",
        "                                     , ('dc_constant_plus', dc_constant_plus)], memory = 'tmp')\n",
        "pipe_most_frequent = Pipeline(steps=[('selector', selector), ('pca', pca)\\\n",
        "                               , ('dc_most_frequent', dc_most_frequent)], memory = 'tmp')\n",
        "pipe_stratified = Pipeline(steps=[('selector', selector), ('pca', pca)\\\n",
        "                               , ('dc_stratified', dc_stratified)], memory = 'tmp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbWCw-RuCWxO",
        "outputId": "fc50328a-83b5-4814-c914-2316db851fbc"
      },
      "source": [
        "pipe_uniform.fit(X_train,Y_train)\n",
        "preds = pipe_uniform.predict(X_test)\n",
        "print(classification_report(Y_test, preds))\n",
        "\n",
        "pipe_constant_minus.fit(X_train,Y_train)\n",
        "preds = pipe_constant_minus.predict(X_test)\n",
        "print(classification_report(Y_test, preds))\n",
        "\n",
        "pipe_constant_plus.fit(X_train,Y_train)\n",
        "preds = pipe_constant_plus.predict(X_test)\n",
        "print(classification_report(Y_test, preds))\n",
        "\n",
        "pipe_most_frequent.fit(X_train,Y_train)\n",
        "preds = pipe_most_frequent.predict(X_test)\n",
        "print(classification_report(Y_test, preds))\n",
        "\n",
        "pipe_stratified.fit(X_train,Y_train)\n",
        "preds = pipe_stratified.predict(X_test)\n",
        "print(classification_report(Y_test, preds))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.49      0.51      0.50        65\n",
            "           -       0.55      0.53      0.54        73\n",
            "\n",
            "    accuracy                           0.52       138\n",
            "   macro avg       0.52      0.52      0.52       138\n",
            "weighted avg       0.52      0.52      0.52       138\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.00      0.00      0.00        65\n",
            "           -       0.53      1.00      0.69        73\n",
            "\n",
            "    accuracy                           0.53       138\n",
            "   macro avg       0.26      0.50      0.35       138\n",
            "weighted avg       0.28      0.53      0.37       138\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.47      1.00      0.64        65\n",
            "           -       0.00      0.00      0.00        73\n",
            "\n",
            "    accuracy                           0.47       138\n",
            "   macro avg       0.24      0.50      0.32       138\n",
            "weighted avg       0.22      0.47      0.30       138\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.00      0.00      0.00        65\n",
            "           -       0.53      1.00      0.69        73\n",
            "\n",
            "    accuracy                           0.53       138\n",
            "   macro avg       0.26      0.50      0.35       138\n",
            "weighted avg       0.28      0.53      0.37       138\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.46      0.43      0.44        65\n",
            "           -       0.52      0.55      0.53        73\n",
            "\n",
            "    accuracy                           0.49       138\n",
            "   macro avg       0.49      0.49      0.49       138\n",
            "weighted avg       0.49      0.49      0.49       138\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11vjrv9mFkgg",
        "outputId": "5c0dcdd3-5a70-4b5b-9455-58906b5462b9"
      },
      "source": [
        "train_variance = X_train.var(axis=0)\n",
        "print(train_variance)\n",
        "print(np.max(train_variance))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.48675540e+02 2.57664565e+01 1.21085398e+01 2.58573271e+01\n",
            " 3.17348285e+04 2.86063047e+07 2.15182603e-01 2.15182603e-01\n",
            " 3.61006091e-03 1.80998608e-01 1.79081994e-01 1.80998608e-01\n",
            " 3.61006091e-03 1.79081994e-01 7.18303665e-02 1.74175593e-01\n",
            " 5.62086484e-02 3.82666457e-02 3.49191346e-02 7.18303665e-02\n",
            " 7.33564377e-02 1.42827137e-02 6.41015543e-02 5.30055398e-02\n",
            " 1.01104679e-01 5.40524575e-03 8.08883375e-02 5.30055398e-02\n",
            " 7.18303665e-02 8.97592418e-03 7.78952689e-02 1.61730729e-01\n",
            " 8.97592418e-03 7.19386683e-03 3.61006091e-03 2.41125814e-01\n",
            " 1.07514178e-02 2.49445363e-01 2.49445363e-01 2.44210775e-01\n",
            " 2.44210775e-01 2.48552694e-01 2.48552694e-01 8.67957099e-02\n",
            " 1.42827137e-02 7.48759452e-02]\n",
            "28606304.730594277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTfNnh9He8Z"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "vthreshold = [0, 1e-03, 1e-02, 1e-01, 1, 1e+01]\n",
        "n_components = [10, 20, 30, 40]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptrx0J6-Hkad",
        "outputId": "76f6caa6-30b5-451c-d2c5-dfc07fc2db9b"
      },
      "source": [
        "import time\n",
        "for pipe in [pipe_uniform, pipe_constant_minus, pipe_constant_plus, pipe_most_frequent, pipe_stratified]:\n",
        "  estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, pca__n_components=n_components),\\\n",
        "                                      cv=10, scoring='f1_macro', n_jobs=-1)\n",
        "  start_time = time.time()\n",
        "  estimator.fit(X_train, Y_train)\n",
        "  preds = estimator.predict(X_test)\n",
        "  print(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))\n",
        "  print(classification_report(Y_test, preds))\n",
        "  print(estimator.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Συνολικός χρόνος fit και predict: 2.425095796585083 seconds\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.51      0.55      0.53        65\n",
            "           -       0.57      0.52      0.54        73\n",
            "\n",
            "    accuracy                           0.54       138\n",
            "   macro avg       0.54      0.54      0.54       138\n",
            "weighted avg       0.54      0.54      0.54       138\n",
            "\n",
            "{'pca__n_components': 10, 'selector__threshold': 0.001}\n",
            "Συνολικός χρόνος fit και predict: 2.4044127464294434 seconds\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.00      0.00      0.00        65\n",
            "           -       0.53      1.00      0.69        73\n",
            "\n",
            "    accuracy                           0.53       138\n",
            "   macro avg       0.26      0.50      0.35       138\n",
            "weighted avg       0.28      0.53      0.37       138\n",
            "\n",
            "{'pca__n_components': 10, 'selector__threshold': 0}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Συνολικός χρόνος fit και predict: 2.4200074672698975 seconds\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.47      1.00      0.64        65\n",
            "           -       0.00      0.00      0.00        73\n",
            "\n",
            "    accuracy                           0.47       138\n",
            "   macro avg       0.24      0.50      0.32       138\n",
            "weighted avg       0.22      0.47      0.30       138\n",
            "\n",
            "{'pca__n_components': 10, 'selector__threshold': 0}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Συνολικός χρόνος fit και predict: 2.4083991050720215 seconds\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.00      0.00      0.00        65\n",
            "           -       0.53      1.00      0.69        73\n",
            "\n",
            "    accuracy                           0.53       138\n",
            "   macro avg       0.26      0.50      0.35       138\n",
            "weighted avg       0.28      0.53      0.37       138\n",
            "\n",
            "{'pca__n_components': 10, 'selector__threshold': 0}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Συνολικός χρόνος fit και predict: 2.4678726196289062 seconds\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.54      0.54      0.54        65\n",
            "           -       0.59      0.59      0.59        73\n",
            "\n",
            "    accuracy                           0.57       138\n",
            "   macro avg       0.56      0.56      0.56       138\n",
            "weighted avg       0.57      0.57      0.57       138\n",
            "\n",
            "{'pca__n_components': 10, 'selector__threshold': 0.1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZL4z5ZPLR7_",
        "outputId": "1052d8ae-0fe5-41f4-e19c-0a6b2d2e0099"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'pca__n_components': 20, 'selector__threshold': 0.001}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJSgyMrHLmca"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
