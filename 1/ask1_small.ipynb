{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ask1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnwrHphPTKxb"
      },
      "source": [
        "# **Νευρωνικά Δίκτυα και Ευφυή Υπολογιστικά Συστήματα**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKFwQ8vuU7mw"
      },
      "source": [
        "## **Άσκηση 1. Επιβλεπόμενη Μάθηση: Ταξινόμηση. Μελέτη datasets του UCI Machine Learning Repository**\n",
        "#### Μαρίνος Τζανίκος 03113147, el13147@mail.ntua.gr\n",
        "#### Γιώργος Γκανάς 03116095, el16095@mail.ntua.gr\n",
        "#### Παναγιώτης Αϊβασιλιώτης 03116176, el16176@mail.ntua.gr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w80g7dM34Sq"
      },
      "source": [
        "!pip install --upgrade pip \n",
        "!pip install --upgrade scikit-learn \n",
        "!pip install --upgrade numpy \n",
        "!pip install --upgrade scipy \n",
        "!pip install --upgrade pandas \n",
        "!pip install --upgrade imbalanced-learn\n",
        "\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqQYtfJStgR2"
      },
      "source": [
        "###**Μικρό Dataset(S)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAfQO7arh_jT"
      },
      "source": [
        "####**Βασικές πληροφορίες**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6rcabbOWNdA"
      },
      "source": [
        "**Εισαγωγή του dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIib37nsYVaV"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"crx.data\", header=None)\n",
        "#Show the first 5 samples of the dataframe\n",
        "df.head(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-YQB8bCYsD5"
      },
      "source": [
        "**Παρουσίαση του dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrDiFSG-Y26E"
      },
      "source": [
        "To dataset περιγράφει την έκβαση των αιτήσεων για πιστωτικές κάρτες με βάση κάποια χαρακτηριστικά.Δηλαδή αν η αίτηση κάποιου για πιστωτική κάρτα, εγκρίθηκε ή όχι.Στόχος μας είναι με χρήση επιβλεπόμενης μάθησης και χωρίς να ξέρουμε την πραγματική ερμηνεία των δεδομένων να δημιουργήσουμε ένα συστήμα που θα μπορεί να χαρακτηρίζει όσο το δυνατόν καλύτερα αν η έκβαση μίας υποψηφίας αίτησης θα είναι θετική ή αρνητική."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1kErmr-hu8A"
      },
      "source": [
        "**Αριθμός δειγμάτων και χαρακτηριστικών, είδος χαρακτηριστικών. Υπάρχουν μη διατεταγμένα χαρακτηριστικά και ποια είναι αυτά;**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4WQVKW1h0tE"
      },
      "source": [
        "Το dataset περιέχει 690 δείγματα.Kάθε δείγμα αποτελείται από 15 χαρακτηριστικά τα οποία είναι κατηγορικά ή αριθμητικά και των οποίων η πραγματική ερμηνεία δεν μας δίνεται.Τα διατεταγμένα χαρακτηριστικά είναι μόνο τα αριθμητικά.Ακόμα κάθε δείγμα περιέχει μία ετικέτα που μας δείχνει την έκβαση που είχε η εν λόγω αίτηση.Πιο συγκεκριμένα έχουμε τα εξής σχετικά με τις πληροφορίες που περιέχει ένα δείγμα:\n",
        "\n",
        "A1:\tb, a.  \n",
        "A2:\tcontinuous.  \n",
        "A3:\tcontinuous.  \n",
        "A4:\tu, y, l, t.  \n",
        "A5:\tg, p, gg.  \n",
        "A6:\tc, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.  \n",
        "A7:\tv, h, bb, j, n, z, dd, ff, o.  \n",
        "A8:\tcontinuous.  \n",
        "A9: t, f.  \n",
        "A10: t, f.  \n",
        "A11: continuous.  \n",
        "A12: t, f.  \n",
        "A13: g, p, s.  \n",
        "A14: continuous.  \n",
        "A15: continuous.  \n",
        "A16: +,- (class attribute)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByUr4FIkGTKW"
      },
      "source": [
        "Επομένως έχουμε οτι τα χαρακτηριστικά Α2,Α3,Α8,Α11,Α14,Α15 είναι συνεχή και τα υπόλοιπα 10 κατηγορικά."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXxtBMr2peAw"
      },
      "source": [
        "**Υπάρχουν επικεφαλίδες; Αρίθμηση γραμμών;**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eimPL-4SpkwX"
      },
      "source": [
        "Όχι, τα δεδομένα μας βρίσκονται σε raw μορφή μέσα στο αρχείο και επομένως δεν έχουν ούτε επικεφαλίδες ούτε αρίθμηση γραμμών."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqlIMs_nq-rH"
      },
      "source": [
        "**Ποιες είναι οι ετικέτες των κλάσεων και σε ποια κολόνα βρίσκονται;**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0amgCbtarCDv"
      },
      "source": [
        "Οι ετικέτες των κλάσεων βρίσκονται στην 16η κολόνα και είναι είτε \"+\" δηλαδή θετική έκβαση της αίτησης είτε \"-\" δηλαδή αρνητική έκβαση της αίτησης."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWuBXSnirgTY"
      },
      "source": [
        "unique_labels = df.iloc[:,-1].unique()\n",
        "print(\"Unique labels of samples: {0}\".format(unique_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWoOVrlssd5l"
      },
      "source": [
        "**Χρειάστηκε να κάνετε μετατροπές στα αρχεία text και ποιες?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nnl53kYNw_OO"
      },
      "source": [
        "Οχι δεν χρειάστηκε να γίνει κάποια μετατροπή στα αρχεία text.Ωστόσο κρίθηκε απαραίτητο να γίνει μία κωδικοποίηση των ετικετών κλάσης από -,+ σε 0,1 ώστε τα δεδομένα μας να είναι συμβατά με το scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRrPkAHvz2N7"
      },
      "source": [
        "labels_df = df.iloc[:,-1] # labels in the last column\n",
        "features_df = df.iloc[:,:-1] # features in all columns but the last\n",
        "\n",
        "mapping = {'-' : 0, '+' : 1} # mapping for labels\n",
        "labels_df = labels_df.replace(mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri788AEJ20nr"
      },
      "source": [
        "**Υπάρχουν απουσιάζουσες τιμές; Πόσα είναι τα δείγματα με απουσιάζουσες τιμές και ποιο το ποσοστό τους επί του συνόλου;**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_xixCOz25w0"
      },
      "source": [
        "Παρατηρούμε ότι οι απουσιάζουσες τιμές εμφανίζονται με \"?\" μέσα στο αρχείο εισόδου και δεν υπάρχει καμία απουσιάζουσα ετικέτα."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwIWHZS53Azv"
      },
      "source": [
        "df.replace('?', np.NaN, inplace=True) # replace all ? with np.NaN\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86knYAaRYs1F"
      },
      "source": [
        "df.isnull().sum().sum() # how many missing values we have"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB2FwlKEZAqR"
      },
      "source": [
        "sum([True for idx,row in df.iterrows() if any(row.isnull())]) # how many samples have missing values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOj1CK0qAv72"
      },
      "source": [
        "Επομένως υπάρχουν συνολικά 67 απουσιάζουσες τιμές σε 37 εκ των δειγμάτων, που αντιστοιχούν στο 5,3% του συνόλου."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hncYyqEvDLJV"
      },
      "source": [
        "**Ποιος είναι ο αριθμός των κλάσεων και τα ποσοστά δειγμάτων τους επί του συνόλου; Αν θεωρήσουμε ότι ένα dataset είναι μη ισορροπημένο αν μια οποιαδήποτε κλάση είναι 1.5 φορά πιο συχνή από κάποια άλλη (60%-40% σε binary datasets) εκτιμήστε την ισορροπία του dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHHIjgd_dgdm"
      },
      "source": [
        "np_labels = labels_df.values.flatten() # convert labels dataframe to numpy array\n",
        "frequencies = np.bincount(np_labels)\n",
        "total_samples = np_labels.shape[0]\n",
        "percentages = (frequencies / total_samples) * 100\n",
        "\n",
        "print(\"Class frequencies: {0}\".format(frequencies))\n",
        "\n",
        "print(\"Class percentages: {0}\".format(percentages))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIS3xaLXf0i2"
      },
      "source": [
        "Βλέπουμε ότι τα ποσοστά δειγμάτων επί του συνόλου των δύο κλάσεων βρίσκονται κοντά στο 50%, επομένως το dataset είναι ισορροπημένο."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnL1IsBSDOg4"
      },
      "source": [
        "**Διαχωρίστε σε train και test set. Εάν υπάρχουν απουσιάζουσες τιμές και μη διατεταγμένα\n",
        "χαρακτηριστικά διαχειριστείτε τα και αιτιολογήστε τις επιλογές σας.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiTNljpTtOrr"
      },
      "source": [
        "Αφού χωρίσουμε το dataset σε train και test set θα αντικαταστήσουμε τις απουσιάζουσες τιμές καθώς η είσοδος στους αλγορίθμους μηχανικής μάθησης πρέπει να είναι πλήρης.Για το λόγο αυτόν,\n",
        "Θα χρησιμοποιήσουμε το μετασχηματιστή “Imputer” του scikit learn που αντικαθιστά κάθε απουσιάζουσα τιμή χαρακτηριστικού με τη μέση τιμή (συνεχείς μεταβλητές) ή την πιο συχνή τιμή (κατηγορικές μεταβλητές).\n",
        "Ο μετασχηματισμός με Imputer γίνεται στην απόλυτη αρχή της προεπεξεργασίας.\n",
        "Ακόμα πρέπει να"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7I-k9wnOh-K"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "#Split our dataframe intο train and test set\n",
        "trainData, testData, trainLabels, testLabels = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.2,stratify=df.iloc[:,-1],random_state=17)\n",
        "\n",
        "#Split dataframes into categorical and continuous features dataframes\n",
        "trainData_continuous = trainData.drop([0,3,4,5,6,8,9,11,12], axis=1)\n",
        "trainData_categorical = trainData.drop([1,2,7,10,13,14], axis=1)\n",
        "testData_continuous = testData.drop([0,3,4,5,6,8,9,11,12], axis=1)\n",
        "testData_categorical = testData.drop([1,2,7,10,13,14], axis=1)\n",
        "\n",
        "#Impute the missing values on continuous features\n",
        "imp = SimpleImputer(missing_values=np.NaN,strategy='mean')\n",
        "itrainData_continuous = pd.DataFrame(imp.fit_transform(trainData_continuous))\n",
        "itrainData_continuous.columns=[1,2,7,10,13,14]\n",
        "itestData_continuous = pd.DataFrame(imp.fit_transform(testData_continuous))\n",
        "itestData_continuous.columns=[1,2,7,10,13,14]\n",
        "\n",
        "#Impute the missing values on categorical features\n",
        "imp = SimpleImputer(missing_values=np.NaN, strategy=\"most_frequent\")\n",
        "itrainData_categorical = pd.DataFrame(imp.fit_transform(trainData_categorical))\n",
        "itrainData_categorical.columns=[0,3,4,5,6,8,9,11,12]\n",
        "itestData_categorical = pd.DataFrame(imp.fit_transform(testData_categorical))\n",
        "itestData_categorical.columns=[0,3,4,5,6,8,9,11,12]\n",
        "\n",
        "#Merge dataframes and reorder indexes to form the original ones imputed\n",
        "itrainData = pd.concat([itrainData_categorical, itrainData_continuous], axis=1)\n",
        "itrainData = itrainData.reindex(sorted(itrainData.columns), axis=1)\n",
        "itestData = pd.concat([itestData_categorical, itestData_continuous], axis=1)\n",
        "itestData = itestData.reindex(sorted(itestData.columns), axis=1)\n",
        "\n",
        "#Convert categorical features to binary , we have to join the two data before this step\n",
        "Data_dummies = pd.get_dummies(pd.concat([itrainData,itestData], join=\"outer\", axis=0),columns=[0,3,4,5,6,8,9,11,12])\n",
        "trainData_dummies = Data_dummies.iloc[:itrainData.shape[0],:]\n",
        "testData_dummies = Data_dummies.iloc[itrainData.shape[0]:,:]\n",
        "\n",
        "#Convert to numeric values and numpy arrays\n",
        "np_trainData = trainData_dummies.apply(pd.to_numeric).values\n",
        "np_testData = testData_dummies.apply(pd.to_numeric).values\n",
        "np_trainLabels = trainLabels.values.flatten()\n",
        "np_testLabels =  testLabels.values.flatten()\n",
        "\n",
        "#Giving symbolic ml names to our arrays \n",
        "X_train = np_trainData\n",
        "y_train = np_trainLabels\n",
        "X_test =  np_testData\n",
        "y_test =  np_testLabels\n",
        "\n",
        "#Four lists to save some metrics along the way\n",
        "before_micro = []\n",
        "before_macro = []\n",
        "after_micro = []\n",
        "after_macro = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eub0WauWiJqH"
      },
      "source": [
        "####**Baseline classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "METAm8-kZlyN"
      },
      "source": [
        "Αρχικά υλοποιήσαμε τους ταξινομητές που ζητούνται χωρίς καμία βελτιστοποίηση στο κόμματι του preproccesing ή των υπερπαραμέτρων του ταξινομητή.\n",
        "\n",
        "Για κάθε ταξινομητή που ζητείται υπολογίσαμε τις μετρικές f1_micro avg και f1_macro avg καθώς και τους πίνακες σύγκρισης για την εκτίμηση του στο test set.Ακόμα για τους ταξινομητές kNN και GNB\n",
        "υπολογίζουμε και την μετρική f1_macro avg με χρηση 10-fold cross validation στο training set ώστε να συγκρίνουμε την απόδοση της βελτιστοποίησης που θα γίνει σε επόμενο βήμα.\n",
        "\n",
        "Για την εμφάνιση των μετρικών χρησιμοποιήσαμε την συνάρτηση `classification_report` του sklearn η οποία εμφανίζει τις μετρικές precision, recall, f1, support για micro avg, macro avg, weighted avg  συνολικά καθώς και για κάθε κλάση ξεχωριστά, υπογραμμίζουμε οτι το micro avg εμφανίζεται ως accuracy.\n",
        "\n",
        "Τέλος παρατηρήσαμε πως το sklearn χρησιμοποιεί StratifiedKFold ως default επιλογή στα binary classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiR2JHNWaLLH"
      },
      "source": [
        "#####**Dummy Classifiers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmpcgGHyS5mb"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dc_uniform = DummyClassifier(strategy=\"uniform\")\n",
        "dc_constant_minus = DummyClassifier(strategy=\"constant\", constant=\"-\")\n",
        "dc_constant_plus = DummyClassifier(strategy=\"constant\", constant=\"+\")\n",
        "dc_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
        "dc_stratified = DummyClassifier(strategy=\"stratified\")\n",
        "\n",
        "dc_uniform.fit(X_train, y_train)\n",
        "dc_constant_minus.fit(X_train, y_train)\n",
        "dc_constant_plus.fit(X_train, y_train)\n",
        "dc_most_frequent.fit(X_train, y_train)\n",
        "dc_stratified.fit(X_train, y_train)\n",
        "\n",
        "pred_uni = dc_uniform.predict(X_test)\n",
        "pred_const_minus = dc_constant_minus.predict(X_test)\n",
        "pred_const_plus = dc_constant_plus.predict(X_test)\n",
        "pred_freq = dc_most_frequent.predict(X_test)\n",
        "pred_strat = dc_stratified.predict(X_test)\n",
        "\n",
        "before_micro.append(precision_recall_fscore_support(y_test, pred_uni, average='micro')[2])\n",
        "before_micro.append(precision_recall_fscore_support(y_test, pred_const_minus, average='micro')[2])\n",
        "before_micro.append(precision_recall_fscore_support(y_test, pred_const_plus, average='micro')[2])\n",
        "before_micro.append(precision_recall_fscore_support(y_test, pred_freq, average='micro')[2])\n",
        "before_micro.append(precision_recall_fscore_support(y_test, pred_strat, average='micro')[2])\n",
        "\n",
        "before_macro.append(precision_recall_fscore_support(y_test, pred_uni, average='macro', zero_division=0)[2])\n",
        "before_macro.append(precision_recall_fscore_support(y_test, pred_const_minus, average='macro', zero_division=0)[2])\n",
        "before_macro.append(precision_recall_fscore_support(y_test, pred_const_plus, average='macro', zero_division=0)[2])\n",
        "before_macro.append(precision_recall_fscore_support(y_test, pred_freq, average='macro', zero_division=0)[2])\n",
        "before_macro.append(precision_recall_fscore_support(y_test, pred_strat, average='macro', zero_division=0)[2])\n",
        "\n",
        "print(\"The DummyClassifier with uniform strategy has score on test set : \\n\" + classification_report(y_test,pred_uni))\n",
        "print(\"The DummyClassifier with constant minus strategy has score on test set : \\n\" + classification_report(y_test,pred_const_minus))\n",
        "print(\"The DummyClassifier with constant plus strategy  has score on test set : \\n\" + classification_report(y_test,pred_const_plus))\n",
        "print(\"The DummyClassifier with frequent strategy has score on test set : \\n\" + classification_report(y_test,pred_freq))\n",
        "print(\"The DummyClassifier with stratified strategy  has score on test set : \\n\" + classification_report(y_test,pred_strat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1aZZmpwaRWO"
      },
      "source": [
        "#####**Gausian Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAIIJwXHeXVm"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "score_gnb = cross_val_score(gnb, X_train, y_train, cv=10, scoring='f1_macro')\n",
        "pred_gnb = gnb.predict(X_test)\n",
        "\n",
        "before_micro.insert(0,precision_recall_fscore_support(y_test, pred_gnb, average='micro')[2])\n",
        "before_macro.insert(0,precision_recall_fscore_support(y_test, pred_gnb, average='macro', zero_division=0)[2])\n",
        "\n",
        "print(\"The GaussianNB Classifier has f1_macro score on training set : %f \\n\" % (score_gnb.mean()))\n",
        "print(\"The GaussianNB Classifier has score on test set : \\n\" + classification_report(y_test,pred_gnb))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t8oNirFaXVy"
      },
      "source": [
        "#####**k Nearest Neighbors Classifier (kNN) με k=5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqe_COT0jl0K"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# kNN Classifier, default k=5\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train,y_train)\n",
        "score_knn = cross_val_score(knn, X_train, y_train, cv=10, scoring=\"f1_macro\")\n",
        "pred_knn = knn.predict(X_test)\n",
        "\n",
        "before_micro.insert(0,precision_recall_fscore_support(y_test, pred_knn, average='micro')[2])\n",
        "before_macro.insert(0,precision_recall_fscore_support(y_test, pred_knn, average='macro', zero_division=0)[2])\n",
        "\n",
        "print(\"The KNeighborsClassifier with k=\" + str(knn.n_neighbors) + \" has f1_macro score on training set : %f \\n\" % (score_knn.mean()))\n",
        "print(\"The KNeighborsClassifier with k=\" + str(knn.n_neighbors) + \" has score on test set : \\n\" + classification_report(y_test,pred_knn))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uweCQCo35CH"
      },
      "source": [
        "#####**Confusion Matrices - Πίνακες Σύγχυσης**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e0r1Ny0YgCP"
      },
      "source": [
        "H συνάρτηση `plot_cnf_clfs` δέχεται ως ορίσματα τους ταξινομητές μαζί με τα predictions που έγιναν για το test set και με την βοηθεια της matplotlib σχεδιάζει τα confusion matrices για τα εν λόγω αποτελέσματα."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyyYl7RP774o"
      },
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_cnf_clfs(clfs, preds, y_test, classes):\n",
        "  for clf, pred in zip(clfs, preds):\n",
        "    clf_name = str(clf).split(\"(\")[0]\n",
        "    if (clf_name == \"Pipeline\"):\n",
        "        clf = clf.steps[-1][1]\n",
        "\n",
        "    clf_name = str(clf).split(\"(\")[0]    \n",
        "    if (clf_name == \"DummyClassifier\"):\n",
        "        clf_name = clf_name + \" strategy=\" + str(clf.strategy)\n",
        "        if (clf.constant == '+' or clf.constant == '-'):\n",
        "          clf_name = clf_name + \" constant=\" + clf.constant\n",
        "    elif (clf_name == \"GaussianNB\"):\n",
        "        clf_name = clf_name\n",
        "    elif (clf_name == \"KNeighborsClassifier\"):\n",
        "        clf_name = clf_name + \" n_neighbors=\" + (str(clf.n_neighbors))\n",
        "    \n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test,pred),display_labels=[\"+\", \"-\"])\n",
        "    disp = disp.plot(include_values=True,cmap=plt.cm.Blues, ax=None, xticks_rotation='horizontal')\n",
        "    disp.ax_.set_title(clf_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HksZcB8NLBgi"
      },
      "source": [
        "#For all classifiers plot the cnf matrix\n",
        "clfs = [knn, gnb, dc_uniform, dc_constant_minus, dc_constant_plus, dc_most_frequent, dc_stratified]\n",
        "preds =[pred_knn, pred_gnb, pred_uni, pred_const_minus, pred_const_plus, pred_freq, pred_strat]\n",
        "plot_cnf_clfs(clfs, preds, y_test,[\"+\", \"-\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL7_FZwY4PlB"
      },
      "source": [
        "#####**Bar Plots για f1 scores**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngVJCIrkhujv"
      },
      "source": [
        "Η συνάρτηση `barplot_clfs` δέχεται ως ορίσματα τους ταξινομητές μαζί με τα predictions που έγιναν για το test set και με την βοηθεια της matplotlib σχεδιάζει τα bar plot των μετρικών f1_micro avg και f1_macro avg για κάθε ταξινομητη."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fJRtyt6TGFg"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def barplot_clfs(clfs, preds, y_test):\n",
        "  #Bar plot values\n",
        "  f1_micros = []\n",
        "  f1_macros = []\n",
        "  clf_names = []\n",
        "  #For each classifier find name,f1_micro,f1_macro and save them\n",
        "  for clf, pred in zip(clfs,preds):\n",
        "    clf_name = str(clf).split(\"(\")[0]\n",
        "    if (clf_name == \"Pipeline\"):\n",
        "        clf = clf.steps[-1][1]\n",
        "    clf_name = str(clf).split(\"(\")[0]\n",
        "    if (clf_name == \"DummyClassifier\"):\n",
        "        clf_name = \"dc \" + clf.strategy\n",
        "        if (clf.constant == '+' or clf.constant == '-'):\n",
        "          clf_name = clf_name + clf.constant\n",
        "    elif (clf_name == \"GaussianNB\"):\n",
        "        clf_name = \"GNB\"\n",
        "    elif (clf_name == \"KNeighborsClassifier\"):\n",
        "       clf_name = \"kNN\" + \" k=\" + (str(clf.n_neighbors))\n",
        "    f1_micro = precision_recall_fscore_support(y_test, pred, average='micro')[2]\n",
        "    f1_macro = precision_recall_fscore_support(y_test, pred, average='macro')[2]\n",
        "    f1_micros.append(f1_micro)\n",
        "    f1_macros.append(f1_macro)\n",
        "    clf_names.append(clf_name)\n",
        "  #Create the 1st plot f1_micro\n",
        "  fig = plt.figure(figsize = (15, 5)) \n",
        "  plt.figure(1)\n",
        "  plt.bar(clf_names, f1_micros,  \n",
        "        width = 0.4)\n",
        "  plt.ylabel(\"f1_micro score\") \n",
        "  plt.title(\"f1_micro\")\n",
        "  #Create the 2nd plot f1_macro\n",
        "  fig = plt.figure(figsize = (15, 5))\n",
        "  plt.figure(2)\n",
        "  plt.bar(clf_names, f1_macros,  \n",
        "        width = 0.4)\n",
        "  plt.ylabel(\"f1_macro score\") \n",
        "  plt.title(\"f1_macro\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9Z2za74XYsk"
      },
      "source": [
        "barplot_clfs(clfs,preds,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiBqM3iSs9Qo"
      },
      "source": [
        "####**Βελτιστοποίηση ταξινομητών**\n",
        "\n",
        "Για κάθε ταξινομητή προσπαθούμε να βελτιώσουμε την απόδοση του στο training set με κάποιον συνδιασμό των VarianceThreshold, StandardScaler, MinMaxScaler και PCA.Ως κριτήριο βελτιστοποίησης θα χρησιμοποιήσουμε την μετρική f1_macro όπως είδαμε και στο εργαστήριο.Αφού επιτεχθούν, θα κάνουμε ένα predict στο test set ώστε να δούμε και την απόδοση του βελτιστοποιήμενου ταξινομητή στο test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMLg8UYlSERc"
      },
      "source": [
        "#####**Dummy Classifiers**\n",
        "\n",
        "Για τη βελτιστοποίηση των dummy ταξινομητών, θα εφαρμόσουμε τα στάδια προεπεξεργασίας VarianceThreshold, StandardScaler και PCA.\n",
        "\n",
        "Για κάθε ταξινομητή κατασκευάζουμε ένα pipe χρησιμοποιώντας αυτούς τους μετασχηματιστές."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCFlBtrmwyfh"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "#from imblearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "#from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "selector = VarianceThreshold()\n",
        "#ros = RandomOverSampler()\n",
        "mscaler = MinMaxScaler()\n",
        "sscaler = StandardScaler()\n",
        "pca = PCA()\n",
        "\n",
        "pipe_uniform = Pipeline(steps=[('selector', selector), ('scaler', sscaler), ('pca', pca)\\\n",
        "                               , ('dc_uniform', dc_uniform)], memory = 'tmp')\n",
        "pipe_constant_minus = Pipeline(steps=[('selector', selector), ('scaler', sscaler), ('pca', pca)\\\n",
        "                                      , ('dc_constant_minus', dc_constant_minus)], memory = 'tmp')\n",
        "pipe_constant_plus = Pipeline(steps=[('selector', selector), ('scaler', sscaler), ('pca', pca)\\\n",
        "                                     , ('dc_constant_plus', dc_constant_plus)], memory = 'tmp')\n",
        "pipe_most_frequent = Pipeline(steps=[('selector', selector), ('scaler', sscaler), ('pca', pca)\\\n",
        "                               , ('dc_most_frequent', dc_most_frequent)], memory = 'tmp')\n",
        "pipe_stratified = Pipeline(steps=[('selector', selector), ('scaler', sscaler), ('pca', pca)\\\n",
        "                               , ('dc_stratified', dc_stratified)], memory = 'tmp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II4OODapTw6q"
      },
      "source": [
        "Στο στάδιο, αυτό εξετάζουμε τα αποτελέσματα της προεπεξεργασίας με default υπερπαραμέτρους,δηλαδή προτού εφαρμόσουμε grid search/cross-validation, ώστε να επιλέξουμε τις βέλτιστες υπερπαραμέτρους. Ωστόσο όπως παρατηρούμε τα αποτελέσματα παραμένουν ίδια (οι διαφορές στους uniform και stratified ταξινομητές προκύπτουν λόγω της τυχαιότητας αυτών) ανεξάρτητα της επιλογής μετασχηματιστών, οπότε για συντομία εδώ παρουσιάζουμε τα αποτελέσματα μόνο για τον πλήρη συνδυασμό."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beVdPgs9T2WZ"
      },
      "source": [
        "pipes_dc = [pipe_uniform, pipe_constant_minus, pipe_constant_plus, pipe_most_frequent, pipe_stratified]\n",
        "\n",
        "for pipe in pipes_dc:\n",
        "  dummy_pipe_name = str(pipe[-1]).split(\"(\")[0]\n",
        "  dummy_pipe_strategy = pipe[-1].strategy\n",
        "  dummy_pipe_constant = pipe[-1].constant\n",
        "  pipe.fit(X_train,y_train)\n",
        "  pipe_pred = pipe.predict(X_test) \n",
        "  if (dummy_pipe_constant == None):\n",
        "    print(\"The DummyClassifier with \" + dummy_pipe_strategy + \" strategy and preprocessing with default parameters has score on test set : \\n\" + classification_report(y_test,pipe_pred))\n",
        "  elif (dummy_pipe_constant == \"+\"):\n",
        "    print(\"The DummyClassifier with \" + dummy_pipe_strategy + \" plus strategy and preprocessing with default parameters has score on test set : \\n\" + classification_report(y_test,pipe_pred))\n",
        "  elif (dummy_pipe_constant == \"-\"):\n",
        "    print(\"The DummyClassifier with \" + dummy_pipe_strategy + \" minus strategy and preprocessing with default parameters has score on test set : \\n\" + classification_report(y_test,pipe_pred))  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgBVVptNUops"
      },
      "source": [
        "Στη συνέχεια θα εκτελέσουμε αναζήτηση πλέγματος στην υπερπαράμετρο threshold του selector και του αριθμού χαρακτηριστικών που δίνει ο PCA. Για να κατασκευάσουμε το κατάλληλο πλέγμα, επισκοπούμε τη διακύμανση των χαρακτηριστικών"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi7SboHg8jOx"
      },
      "source": [
        "train_variance = X_train.var(axis=0)\n",
        "train_variance.sort()\n",
        "print(train_variance)\n",
        "print(np.max(train_variance))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR4GY2yKcTMt"
      },
      "source": [
        "Στη φάση αυτή, εκτελούμε την αναζήτηση πλέγματος στα pipes των dummy ταξινομητών και εφαρμόζουμε τα αποτελέσματα στα δεδομένα. Δεχόμαστε έτσι τις τελικές μετρικές των βελτιστοποιημένων ταξινομητών."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqNtlhUQ8tkQ"
      },
      "source": [
        "import time\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Grid Search for dummy classifiers\n",
        "vthreshold = [0, 1e-02, 6e-02, 1e-01, 2e-01, 1]\n",
        "n_components = [2, 10, 20, 30, 40, 45]\n",
        "\n",
        "pred_pipes_dc = []\n",
        "time_pipes_dc = []\n",
        "for pipe in pipes_dc:\n",
        "  dummy_name = str(pipe[-1]).split(\"(\")[0]\n",
        "  dummy_strategy = pipe[-1].strategy\n",
        "  dummy_constant = pipe[-1].constant\n",
        "  estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, pca__n_components=n_components),\\\n",
        "                                      cv=10, scoring='f1_macro', n_jobs=-1)\n",
        "  start_time = time.time()\n",
        "  estimator.fit(X_train, y_train)\n",
        "  pred = estimator.predict(X_test)\n",
        "  pred_pipes_dc.append(pred)\n",
        "  time_pipes_dc.append(time.time() - start_time)\n",
        "  if (dummy_constant == None):\n",
        "    print(\"The optimized DummyClassifier with \" + dummy_strategy + \" strategy has score on test set : \\n\" + classification_report(y_test,pred))\n",
        "  elif (dummy_constant == \"+\"):\n",
        "    print(\"The optimized DummyClassifier with \" + dummy_strategy + \" plus strategy has score on test set : \\n\" + classification_report(y_test,pred))\n",
        "  elif (dummy_constant == \"-\"):\n",
        "    print(\"The optimized DummyClassifier with \" + dummy_strategy + \" minus strategy has score on test set : \\n\" + classification_report(y_test,pred))\n",
        "  print(\"with best parameters\")\n",
        "  print(estimator.best_params_)\n",
        "  print(\"\\n\")\n",
        "  after_micro.append(precision_recall_fscore_support(y_test, pred, average='micro')[2])\n",
        "  after_macro.append(precision_recall_fscore_support(y_test, pred, average='macro', zero_division=0)[2])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc8HEiy8pXdO"
      },
      "source": [
        "Παρατηρούμε όμως ότι πάλι τα αποτελέσματα δεν είναι διαφορετικά, παρά την προσπάθεια βελτιστοποίησης. Αυτό όμως είναι και το αναμενόμενο αποτέλεσμα, αφού οι dummy ταξινομητές δεν εξετάζουν τα δεδομένα σε αρκετό βάθος ώστε να έχει σημασία η προεπεξεργασία. Συγκεκριμένα, οι σταθεροί ταξινομητές, προφανώς θα έχουν πάντα την ίδια απόδοση, ενώ και ο most frequent διατηρεί τα ίδια αποτελέσματα, εφόσον η πιο συχνή ετικέτα δεν αλλάζει. Όσο για τους uniform και stratified ταξινομητές, παρατηρείται μία απόκλιση από το αρχικά αποτελέσματα, ωστόσο αυτή είναι κάθε φορά διαφορετική και τυχαία. Εντελώς, στην πρώτη περίπτωση, ενώ στη δεύτερη αφού δεν αφαιρούμε γραμμές από τα δεδομένα μας, οι προβλέψεις θα γίνονται πάντα με την ίδια πιθανότητα."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NEYBa9DrjJM"
      },
      "source": [
        "#####**Gaussian Naives Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBZvvDqts5AH"
      },
      "source": [
        "pipe_gnb = Pipeline(steps=[('selector', selector), ('mscaler', mscaler), ('pca', pca), ('gnb', gnb)],memory=\"tmp\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDGraa31sy8E"
      },
      "source": [
        "Όπως πριν θα εξέτασουμε τα αποτελέσματα της προεπεξεργασίας προτού γίνει αναζήτηση βέλτιστων υπερπαραμέτρων."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofx3N1qBs8mq"
      },
      "source": [
        "pipe_gnb.fit(X_train, y_train)\n",
        "pred_pipe_gnb = pipe_gnb.predict(X_test)\n",
        "score_pipe_gnb = cross_val_score(pipe_gnb, X_train, y_train, cv=10, scoring='f1_macro')\n",
        "\n",
        "print(\"The GaussianNB Classifier with default preprocessing has f1_macro score on training set : %f \\n\" % (score_pipe_gnb.mean()))\n",
        "print(\"The GaussianNB Classifier with default preprocessing parameters: \\n\" + classification_report(y_test,pred_pipe_gnb))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxjg3iwKxROX"
      },
      "source": [
        "Εδώ βλέπουμε πως ο ίδιος ταξινομητής μαζί με την προεπεξεργασία με τις default υπερπαραμέτρους έχει μικρότερη απόδοση στο training set.Παράλληλα βλέπουμε οτι η απόδοση στο test set έχει επίσης μικρύνει."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffQ3PjXNx8yv"
      },
      "source": [
        "Έπειτα θα εφαρμόσουμε αναζήτηση πλέγματος ώστε να βρούμε τις βέλτιστες υπερπαραμέτρους για την προεπεξεργασία για τις οποίες θα έχουμε ακόμα καλύτερη αποδοσή απο τον ταξινομητή χωρίς προεπεξεργασία."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4b2AwgvxRbI"
      },
      "source": [
        "vthreshold = [0, 1e-02, 6e-02, 1e-01, 2e-01, 1]\n",
        "n_components = [2, 10, 20, 30, 40, 45]\n",
        "\n",
        "estimator = GridSearchCV(pipe_gnb, dict(selector__threshold=vthreshold, pca__n_components=n_components), cv=10, scoring='f1_macro',n_jobs=-1)\n",
        "start_time = time.time()\n",
        "estimator.fit(X_train,y_train)\n",
        "pred_pipe_gnb = estimator.predict(X_test)\n",
        "time_pipe_gnb = time.time()-start_time\n",
        "print(\"The optimized GaussianNB Classifier has f1_macro score on training set : %f \\n\" % (estimator.best_score_))\n",
        "print(\"The optimized GaussianNB Classifier : \\n\" + classification_report(y_test,pred_pipe_gnb))\n",
        "print(\"with best parameters\")\n",
        "print(estimator.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw4z6cUzQY_5"
      },
      "source": [
        "Θα ελέγξουμε αν υπάρχει περιθώριο βελτίωσης του ταξινομήτη ελέγχοντας κάποιες τιμές κοντά στις τιμές που βρήκαμε, πραγματοποιώντας ουσιαστικά μία progressive αναζήτηση πλέγματος."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA6klVEMqwCp"
      },
      "source": [
        "vthreshold = [3e-02, 6e-02, 9e-02]\n",
        "n_components = [6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
        "\n",
        "estimator = GridSearchCV(pipe_gnb, dict(selector__threshold=vthreshold, pca__n_components=n_components), cv=10, scoring='f1_macro',n_jobs=-1)\n",
        "estimator.fit(X_train,y_train)\n",
        "pred_pipe_gnb = estimator.predict(X_test)\n",
        "print(\"The optimized GaussianNB Classifier has f1_macro score on training set : %f \\n\" % (estimator.best_score_))\n",
        "print(\"The optimized GaussianNB Classifier : \\n\" + classification_report(y_test,pred_pipe_gnb))\n",
        "print(\"with best parameters\")\n",
        "print(estimator.best_params_)\n",
        "after_micro.insert(0, precision_recall_fscore_support(y_test, pred_pipe_gnb, average='micro')[2])\n",
        "after_macro.insert(0, precision_recall_fscore_support(y_test, pred_pipe_gnb, average='macro', zero_division=0)[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0ICfwc5ROnG"
      },
      "source": [
        "Πράγματι βλέπουμε πως έχουμε βελτίωση της απόδοσης του ταξινομητή στο training set σχεδον 2% απο τον απλό GNB.Ενω στο test set λαμβάνουμε απόδοση κοντά στο 90%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqVJujH94q5y"
      },
      "source": [
        "#####**k Nearest Neighbors Classifier (kNN)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoMMaer6r7v1"
      },
      "source": [
        "pipe_knn = Pipeline(steps=[('selector', selector), ('mscaler',mscaler), ('pca', pca), ('knn', knn)],memory=\"tmp\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnVHeKCJ59jm"
      },
      "source": [
        "Όπως πριν θα εξέτασουμε τα αποτελέσματα της προεπεξεργασίας προτού γίνει αναζήτηση βέλτιστων υπερπαραμέτρων."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gyPBiGvUXyj"
      },
      "source": [
        "pipe_knn.fit(X_train,y_train)\n",
        "pred_pipe_knn = pipe_knn.predict(X_test)\n",
        "score_pipe_knn = cross_val_score(pipe_knn, X_train, y_train, cv=10, scoring='f1_macro')\n",
        "print(\"The KNeighborsClassifier with k=\" + str(pipe_knn[-1].n_neighbors) + \" and default preprocessing parameters has f1_macro score on training set : %f \\n\" % (score_pipe_knn.mean()))\n",
        "print(\"The KNeighborsClassifier with k=\" + str(pipe_knn[-1].n_neighbors) + \" and default preprocessing parameters has score on test set : \\n\" + classification_report(y_test,pred_pipe_knn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZBJl5-xctSc"
      },
      "source": [
        "Εδώ βλέπουμε πως ο ίδιος ταξινομητής μαζί με την προεπεξεργασία βελτίωσε την απόδοση του σχεδόν κατα 18%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sR7308CUxyr"
      },
      "source": [
        "Έπειτα θα εφαρμόσουμε progressive αναζήτηση πλέγματος ώστε να βελτιστοποιήσουμε τον ταξινομητή επιλέγοντας τις βέλτιστες υπερπαραμέτρους για την προεπεξεργασία και την υπερπαράμετρο k του kNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHxlPXKM_Er8"
      },
      "source": [
        "#Grid for knn classifier\n",
        "vthreshold = [0, 1e-02, 6e-02, 1e-01, 2e-01, 1]\n",
        "n_components = [2, 10, 20, 30, 40, 45]\n",
        "k = [1, 5, 11, 15, 21, 25, 31, 35, 41]\n",
        "\n",
        "start_time = time.time()\n",
        "estimator = GridSearchCV(pipe_knn, dict(selector__threshold=vthreshold, pca__n_components=n_components, knn__n_neighbors=k),\\\n",
        "                         cv=10, scoring='f1_macro', n_jobs=-1)\n",
        "estimator.fit(X_train,y_train)\n",
        "pred_pipe_knn = estimator.predict(X_test)\n",
        "time_pipe_knn = time.time() - start_time\n",
        "print(\"The optimized KNeighborsClassifier has f1_macro score on training set %f : \\n\" % (estimator.best_score_))\n",
        "print(\"The optimized KNeighborsClassifier has score on test set : \\n\" + classification_report(y_test,pred_pipe_knn))\n",
        "print(\"with best parameters\")\n",
        "print(estimator.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A3xIDkOpdVY"
      },
      "source": [
        "Επαναλαμβάνουμε τώρα την αναζήτηση πλέγματος με τιμές υπερπαραμέτρων κοντινές στις βέλτιστες της προηγούμενης αναζήτησης."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLr-A0vooXVA"
      },
      "source": [
        "#Grid for knn classifier\n",
        "vthreshold = [0, 2e-03, 4e-03]\n",
        "n_components = [17, 18, 19, 20, 21, 22, 23]\n",
        "k = [3, 5, 7, 9]\n",
        "\n",
        "estimator = GridSearchCV(pipe_knn, dict(selector__threshold=vthreshold, pca__n_components=n_components, knn__n_neighbors=k),\\\n",
        "                         cv=10, scoring='f1_macro', n_jobs=-1)\n",
        "estimator.fit(X_train,y_train)\n",
        "pred_pipe_knn = estimator.predict(X_test)\n",
        "print(\"The optimized KNeighborsClassifier has f1_macro score on training set %f : \\n\" % (estimator.best_score_))\n",
        "print(\"The optimized KNeighborsClassifier : \\n\" + classification_report(y_test,pred_pipe_knn))\n",
        "print(\"with best parameters\")\n",
        "print(estimator.best_params_)\n",
        "after_micro.insert(0, precision_recall_fscore_support(y_test, pred_pipe_knn, average='micro')[2])\n",
        "after_macro.insert(0, precision_recall_fscore_support(y_test, pred_pipe_knn, average='macro', zero_division=0)[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esgy2-gWp7H7"
      },
      "source": [
        "Καταλήγουμε οτι οι βέλτιστες υπερπαράμετροι είναι πολυ κοντά σε αυτές που βρήκαμε και στο προηγούμενο βήμα.Η μόνη υπερπαράμετρος που άλλαξε είναι το vthreshhold ωστόσο η απόδοση έμεινε ίδια.\n",
        "Οπότε το παρόν βήμα αποτελεί μία επαλήθευση οτι βρισκόμαστε σε καλό συνδυασμό υπερπαραμέτρων."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xv8Wxgooa-J"
      },
      "source": [
        "#####**Confusion Matrices - Πίνακες Σύγχυσης**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ayq-wbSqBFW"
      },
      "source": [
        "#For all classifiers plot the cnf matrix\n",
        "clfs = [pipe_knn, pipe_gnb] + (pipes_dc)\n",
        "preds =[pred_pipe_knn, pred_pipe_gnb] + (pred_pipes_dc) \n",
        "plot_cnf_clfs(clfs, preds, y_test,[\"+\", \"-\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t_sG3pasyzp"
      },
      "source": [
        "#####**Χρόνοι εκτέλεσης**\n",
        "\n",
        "Ακολουθούν οι χρόνοι που χρειάστηκαν για την εκπαίδευση και εκτίμηση του κάθε ταξινομητή.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uwK-lJZt6mi"
      },
      "source": [
        "#Create a list with the times for fit and predict\n",
        "times = [time_pipe_knn] + [time_pipe_gnb] + time_pipes_dc\n",
        "\n",
        "#Save the names of the classifiers\n",
        "names = []\n",
        "for clf in clfs:\n",
        "  clf_name = str(clf).split(\"(\")[0]\n",
        "  if (clf_name == \"Pipeline\"):\n",
        "      clf = clf.steps[-1][1]\n",
        "  clf_name = str(clf).split(\"(\")[0]    \n",
        "  if (clf_name == \"DummyClassifier\"):\n",
        "      clf_name = clf_name + \" strategy=\" + str(clf.strategy)\n",
        "      if (clf.constant == '+' or clf.constant == '-'):\n",
        "        clf_name = clf_name + \" constant=\" + clf.constant\n",
        "  elif (clf_name == \"GaussianNB\"):\n",
        "      clf_name = clf_name\n",
        "  elif (clf_name == \"KNeighborsClassifier\"):\n",
        "      clf_name = clf_name + \" n_neighbors=\" + (str(clf.n_neighbors))\n",
        "  names.append(clf_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxIprkn10RQB"
      },
      "source": [
        "pd.DataFrame({'Time (s)': times}, index=names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTfki29f1kzW"
      },
      "source": [
        "#####**Bar Plots για f1 scores**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcYuEKgM2CoS"
      },
      "source": [
        "barplot_clfs(clfs,preds,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy3YcdCb2vKu"
      },
      "source": [
        "#####**Πίνακας μεταβολής απόδοσης**\n",
        "\n",
        "Ο παρακάτω πίνακας μας δείχνει την μεταβολή της απόδοσης στο test set (μετρικές f1_micro και f1_macro) πριν και μετά την βελτιστοποίηση των ταξινομητών.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Owy0SS3XEm"
      },
      "source": [
        "changes = {\n",
        "    'Before F1 (micro)': before_micro,\n",
        "    'After F1 (micro)': after_micro,\n",
        "    'Before F1 (macro)': before_macro,\n",
        "    'After F1 (macro)': after_macro\n",
        "}\n",
        "pd.DataFrame(changes, index=names)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}